<h1 align="center">🧠 GenVox</h1>
<h3 align="center">🎙️ A Voice-Activated Multimodal Generative AI Companion 🎨🔊</h3>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.0-blue?logo=python&style=flat-square" />
  <img src="https://img.shields.io/badge/Kivy-GUI-success?style=flat-square" />
  <img src="https://img.shields.io/badge/TogetherAI-API-orange?style=flat-square" />
  <img src="https://img.shields.io/badge/HuggingFace-Models-yellow?style=flat-square" />
</p>

---

## 📖 About the Project

**GenVox** is a voice-activated **multimodal generative AI companion** that seamlessly integrates:

- 🧠 Natural language understanding  
- 🎨 Image generation  
- 🔊 Audio synthesis  

This powerful assistant enables users to **create, ask, and interact** using **just their voice**, delivering outputs in multiple formats:  
**Text**, **Image**, and **Audio**.

Use GenVox as a:

- 🧑‍💼 Personal Assistant  
- 🎨 Creative Collaborator  
- 🎓 Learning Partner  

It combines the best of LLMs (like **Llama 3**), **gTTS**, and generative APIs from **Together.ai** and **Hugging Face** to make AI content creation **intuitive and voice-driven**.

---

## ✨ Core Features

✅ **Voice-to-Text Generation** – Stories, summaries, Q&A, blog writing  
✅ **Voice-to-Image Creation** – Create art and illustrations from spoken prompts  
✅ **Voice-to-Audio Conversion** – Speak content using natural TTS engines  
✅ **Cross-Modal AI** – Blend voice, text, image, and audio generation in real-time  
✅ **Hands-free Commanding** – No typing needed!

---

## ⚙️ Technologies Used

| Tool | Use |
|------|-----|
| 🐍 Python 3.0 | Backend Development |
| 🎛️ Kivy / KivyMD | GUI (Desktop & Android) |
| 🧠 Llama-3.0-Turbo | Text generation |
| 🗣️ SpeechRecognition | Voice Input |
| 🔊 gTTS / pyttsx3 | Text-to-Speech |
| 🎨 Hugging Face APIs | Image Generation |
| ☁️ Together.ai | LLM APIs |
| 🗃️ PyMongo | Data Storage (Optional) |

---

## 🛠️ Installation

```bash
# 1. Clone the repository
git clone https://github.com/manikantaa1/Genvox.git
cd Genvox

# 2. (Optional) Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# 3. Install dependencies
pip install -r requirements.txt
